{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    balanced_accuracy_score,\n",
        "    classification_report,\n",
        "    precision_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "JKR9QUIkRSHe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drug Consumption dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00373/drug_consumption.data\"\n",
        "columns = [\n",
        "    \"ID\", \"Age\", \"Gender\", \"Education\", \"Country\", \"Ethnicity\", \"Neuroticism\", \"Extraversion\",\n",
        "    \"Openness\", \"Agreeableness\", \"Conscientiousness\", \"Impulsiveness\", \"Sensation-seeking\",\n",
        "    \"Alcohol\", \"Amphetamines\", \"Amyl_nitrite\", \"Benzodiazepines\", \"Caffeine\", \"Cannabis\",\n",
        "    \"Chocolate\", \"Cocaine\", \"Crack\", \"Ecstasy\", \"Heroin\", \"Ketamine\", \"Legal_highs\", \"LSD\",\n",
        "    \"Methadone\", \"Mushrooms\", \"Nicotine\", \"Semer\", \"Volatile_substance\"\n",
        "]\n",
        "data = pd.read_csv(url, header=None, names=columns)"
      ],
      "metadata": {
        "id": "Z2L1pJT_RUsv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target (Y) and bias group (B)\n",
        "target = \"Cannabis\"\n",
        "bias_group = \"Ethnicity\"\n",
        "\n",
        "# Binarize the target and bias group\n",
        "data[target] = data[target].apply(lambda x: 1 if x in [\"CL3\", \"CL4\", \"CL5\", \"CL6\"] else 0)\n",
        "data[bias_group] = data[bias_group].apply(lambda x: 1 if x > -0.5 else 0)"
      ],
      "metadata": {
        "id": "vuQgSrfuRUwh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess categorical features\n",
        "categorical_columns = data.select_dtypes(include=[\"object\"]).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    encoder = LabelEncoder()\n",
        "    data[col] = encoder.fit_transform(data[col])\n",
        "    label_encoders[col] = encoder\n",
        "\n",
        "# Ensure all columns are numeric\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == \"object\":\n",
        "        data[col] = pd.to_numeric(data[col], errors=\"coerce\")"
      ],
      "metadata": {
        "id": "nVW7yGJ8RU0G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define features and target for training and testing\n",
        "X_train = train_data.drop(columns=[target, bias_group])\n",
        "y_train = train_data[target]\n",
        "X_test = test_data.drop(columns=[target, bias_group])\n",
        "y_test = test_data[target]\n",
        "\n",
        "# Convert features to float to avoid type issues\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)"
      ],
      "metadata": {
        "id": "PakXC-6iRU3o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data for KNN and Logistic Regression\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "RV19J3buRU7R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, group, model_name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\n{model_name} - Regular Data\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.2f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Fairness metrics\n",
        "    equalized_odds = calculate_equalized_odds(y_test, y_pred, group)\n",
        "    predictive_parity = calculate_predictive_value_parity(y_test, y_pred, group)\n",
        "\n",
        "    print(\"\\nEqualized Odds (TPR, FPR) by Group:\")\n",
        "    for g, metrics in equalized_odds.items():\n",
        "        print(f\"Group {g}: TPR = {metrics['TPR']:.2f}, FPR = {metrics['FPR']:.2f}\")\n",
        "\n",
        "    print(\"\\nPredictive Parity (PPV) by Group:\")\n",
        "    for g, ppv in predictive_parity.items():\n",
        "        print(f\"Group {g}: PPV = {ppv:.2f}\")\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "5fAVknCeRVAh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_equalized_odds(y_true, y_pred, group):\n",
        "    tpr_fpr = defaultdict(dict)\n",
        "    unique_groups = np.unique(group)\n",
        "\n",
        "    for g in unique_groups:\n",
        "        mask = group == g\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true[mask], y_pred[mask]).ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # Fall-out\n",
        "        tpr_fpr[g] = {\"TPR\": tpr, \"FPR\": fpr}\n",
        "\n",
        "    return tpr_fpr"
      ],
      "metadata": {
        "id": "qjkKwfDaRVJR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_predictive_value_parity(y_true, y_pred, group):\n",
        "    ppv = {}\n",
        "    unique_groups = np.unique(group)\n",
        "\n",
        "    for g in unique_groups:\n",
        "        mask = group == g\n",
        "        precision = precision_score(y_true[mask], y_pred[mask], zero_division=0)\n",
        "        ppv[g] = precision\n",
        "\n",
        "    return ppv"
      ],
      "metadata": {
        "id": "_7Isc8-0SSj2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_regular = KNeighborsClassifier(n_neighbors=5)\n",
        "y_pred_knn_regular = train_and_evaluate_model(\n",
        "    knn_regular, X_train_scaled, y_train, X_test_scaled, y_test, test_data[bias_group], \"KNN Model\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnjoqW84SSuM",
        "outputId": "489b3e9d-6110-4ab2-cf2a-d6af1fe37b3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KNN Model - Regular Data\n",
            "Accuracy: 0.83\n",
            "Balanced Accuracy: 0.83\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82       249\n",
            "           1       0.88      0.80      0.84       317\n",
            "\n",
            "    accuracy                           0.83       566\n",
            "   macro avg       0.83      0.83      0.83       566\n",
            "weighted avg       0.83      0.83      0.83       566\n",
            "\n",
            "\n",
            "Equalized Odds (TPR, FPR) by Group:\n",
            "Group 0: TPR = 0.83, FPR = 0.08\n",
            "Group 1: TPR = 0.80, FPR = 0.14\n",
            "\n",
            "Predictive Parity (PPV) by Group:\n",
            "Group 0: PPV = 0.83\n",
            "Group 1: PPV = 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_regular = RandomForestClassifier(random_state=42)\n",
        "y_pred_rf_regular = train_and_evaluate_model(\n",
        "    rf_regular, X_train, y_train, X_test, y_test, test_data[bias_group], \"Random Forest Model\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSM9tgECSSxa",
        "outputId": "943cc8c0-1c03-462c-a992-76fa401d4252"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Model - Regular Data\n",
            "Accuracy: 0.88\n",
            "Balanced Accuracy: 0.88\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86       249\n",
            "           1       0.89      0.90      0.89       317\n",
            "\n",
            "    accuracy                           0.88       566\n",
            "   macro avg       0.88      0.88      0.88       566\n",
            "weighted avg       0.88      0.88      0.88       566\n",
            "\n",
            "\n",
            "Equalized Odds (TPR, FPR) by Group:\n",
            "Group 0: TPR = 1.00, FPR = 0.08\n",
            "Group 1: TPR = 0.89, FPR = 0.15\n",
            "\n",
            "Predictive Parity (PPV) by Group:\n",
            "Group 0: PPV = 0.86\n",
            "Group 1: PPV = 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regular = LogisticRegression(random_state=42, max_iter=1000)\n",
        "y_pred_logistic_regular = train_and_evaluate_model(\n",
        "    logistic_regular, X_train_scaled, y_train, X_test_scaled, y_test, test_data[bias_group], \"Logistic Regression Model\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hpAC-MjSS1r",
        "outputId": "dc1407c3-d4c5-4880-9afd-cac742474600"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Model - Regular Data\n",
            "Accuracy: 0.85\n",
            "Balanced Accuracy: 0.85\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83       249\n",
            "           1       0.89      0.83      0.86       317\n",
            "\n",
            "    accuracy                           0.85       566\n",
            "   macro avg       0.84      0.85      0.85       566\n",
            "weighted avg       0.85      0.85      0.85       566\n",
            "\n",
            "\n",
            "Equalized Odds (TPR, FPR) by Group:\n",
            "Group 0: TPR = 1.00, FPR = 0.08\n",
            "Group 1: TPR = 0.83, FPR = 0.14\n",
            "\n",
            "Predictive Parity (PPV) by Group:\n",
            "Group 0: PPV = 0.86\n",
            "Group 1: PPV = 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data[target].unique()\n",
        "bias_groups = train_data[bias_group].unique()\n",
        "subsampled_distributions = {}\n",
        "\n",
        "for c in classes:\n",
        "    class_c_data = train_data[train_data[target] == c]\n",
        "    bias_distribution = class_c_data[bias_group].value_counts(normalize=True)\n",
        "    subsampled_data = []\n",
        "    for other_c in classes:\n",
        "        if other_c == c:\n",
        "            subsampled_data.append(class_c_data)\n",
        "        else:\n",
        "            other_class_data = train_data[train_data[target] == other_c]\n",
        "            sampled = []\n",
        "            for bg in bias_groups:\n",
        "                target_count = int(bias_distribution[bg] * len(other_class_data))\n",
        "                sampled.append(other_class_data[other_class_data[bias_group] == bg].sample(n=target_count, replace=True))\n",
        "            subsampled_data.append(pd.concat(sampled))\n",
        "    subsampled_distributions[c] = pd.concat(subsampled_data)"
      ],
      "metadata": {
        "id": "H41YzfYnSiXK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bias_mitigated_model(model_class, model_args, subsampled_distributions):\n",
        "    bias_clfs = {}\n",
        "    for c, subset in subsampled_distributions.items():\n",
        "        X_train_bm = subset.drop(columns=[target, bias_group])\n",
        "        y_train_bm = subset[target]\n",
        "        X_train_bm_scaled = scaler.fit_transform(X_train_bm)\n",
        "\n",
        "        if len(y_train_bm.unique()) == 1:\n",
        "            print(f\"Warning: Only one class present in training data for class {c}. Using constant probabilities.\")\n",
        "            bias_clfs[c] = None\n",
        "        else:\n",
        "            model = model_class(**model_args)\n",
        "            model.fit(X_train_bm_scaled, y_train_bm)\n",
        "            bias_clfs[c] = model\n",
        "    return bias_clfs"
      ],
      "metadata": {
        "id": "n7m4lhlPSiaI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias_knn_clfs = train_bias_mitigated_model(KNeighborsClassifier, {\"n_neighbors\": 5}, subsampled_distributions)\n",
        "bias_rf_clfs = train_bias_mitigated_model(RandomForestClassifier, {\"random_state\": 42}, subsampled_distributions)\n",
        "bias_logistic_clfs = train_bias_mitigated_model(LogisticRegression, {\"random_state\": 42, \"max_iter\": 1000}, subsampled_distributions)"
      ],
      "metadata": {
        "id": "v2y_2nkJSidz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bias_mitigated_model(clfs, X_test, y_test, group, model_name):\n",
        "    bias_predictions = []\n",
        "    for c, clf in clfs.items():\n",
        "        if clf is None:\n",
        "            constant_prob = 1 if train_data[train_data[target] == c][target].iloc[0] == 1 else 0\n",
        "            bias_predictions.append(np.full(len(X_test), constant_prob))\n",
        "        else:\n",
        "            bias_predictions.append(clf.predict_proba(X_test)[:, 1])\n",
        "    final_bias_predictions = np.argmax(bias_predictions, axis=0)\n",
        "    accuracy = accuracy_score(y_test, final_bias_predictions)\n",
        "    balanced_acc = balanced_accuracy_score(y_test, final_bias_predictions)\n",
        "    print(f\"\\n{model_name} - Bias-Mitigated Data\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.2f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, final_bias_predictions))\n",
        "    equalized_odds = calculate_equalized_odds(y_test, final_bias_predictions, group)\n",
        "    predictive_parity = calculate_predictive_value_parity(y_test, final_bias_predictions, group)\n",
        "    print(\"\\nEqualized Odds (TPR, FPR) by Group:\")\n",
        "    for g, metrics in equalized_odds.items():\n",
        "        print(f\"Group {g}: TPR = {metrics['TPR']:.2f}, FPR = {metrics['FPR']:.2f}\")\n",
        "    print(\"\\nPredictive Parity (PPV) by Group:\")\n",
        "    for g, ppv in predictive_parity.items():\n",
        "        print(f\"Group {g}: PPV = {ppv:.2f}\")"
      ],
      "metadata": {
        "id": "N9r6RyqfSig_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bias_mitigated_model(bias_knn_clfs, X_test_scaled, y_test, test_data[bias_group], \"KNN Model\")"
      ],
      "metadata": {
        "id": "SWCU2UcQSikJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bias_mitigated_model(bias_rf_clfs, X_test, y_test, test_data[bias_group], \"Random Forest Model\")"
      ],
      "metadata": {
        "id": "b69NzxRwSioN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bias_mitigated_model(bias_logistic_clfs, X_test_scaled, y_test, test_data[bias_group], \"Logistic Regression Model\")"
      ],
      "metadata": {
        "id": "8Li4RfBhSirA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}